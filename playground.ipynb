{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground\n",
    "\n",
    "My playground, for learning / debugging / visualizing purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look up dataset images: in a simple way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path as osp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/\"\n",
    "dataset_path = osp.join(data_path, 'CVACT_full', 'streetview')\n",
    "dataset_filenames = sorted(os.listdir(dataset_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(dataset_path, filenames, idx):\n",
    "    img_path = osp.join(dataset_path, filenames[idx])\n",
    "    img = np.asarray(Image.open(img_path))\n",
    "    print(f'\\tFile path: {img_path}')\n",
    "    print(f'\\tImage shape: {img.shape}')\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "def look_dataset(dataset_path, filenames, s=0, l=100):\n",
    "    print(f'Dataset path: {dataset_path}')\n",
    "    print(f'Number of images in {dataset_path}: {len(dataset_filenames)}')\n",
    "    print(f'Current visualizing range: {s} - {s + l}')\n",
    "    widgets.interact(lambda idx: show_img(dataset_path, filenames, idx),\n",
    "                     idx=widgets.IntSlider(min=s, max=min(len(dataset_filenames) - 1, s + l), step=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: ./data/CVACT_full/streetview\n",
      "Number of images in ./data/CVACT_full/streetview: 128331\n",
      "Current visualizing range: 300 - 400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845e0613ad254f8eb70f80816a65f0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=300, description='idx', max=400, min=300), Output()), _dom_classes=('wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "look_dataset(dataset_path, dataset_filenames, 300, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look up CVACT dataset: interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from orissl_cvm.datasets.cvact_dataset import CVACTDataset\n",
    "from orissl_cvm.utils.tools import input_transform\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construct neighbor searches: kd_tree\n",
      "Finding positive neighbors for 8646 queries\n",
      "Finding non-negative neighbors for 8646 queries\n"
     ]
    }
   ],
   "source": [
    "root_dir = Path('./data/CVACT_full/').absolute()\n",
    "\n",
    "train_dataset = CVACTDataset(root_dir, \n",
    "                             mode='train', \n",
    "                             nNeg=3, \n",
    "                             transform=input_transform(),\n",
    "                             bs=32, \n",
    "                             threads=6, \n",
    "                             margin=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_dataset.qIdx)\n",
    "# print(train_dataset.pIdx)\n",
    "# print(train_dataset.nonNegIdx)\n",
    "# print(train_dataset.posDistThr)\n",
    "# print(train_dataset.negDistThr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from orissl_cvm.models.siamese import GoodNet\n",
    "import torch\n",
    "\n",
    "config = {\n",
    "    'global_params': {'pooling': 'max'}\n",
    "}\n",
    "checkpoint = torch.load(\"work_dirs/Apr05_12-36-10_cvact_resnet50/checkpoints/checkpoint.pth.tar\", map_location=lambda storage, loc: storage)\n",
    "model = GoodNet(config['global_params'])\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divides dataset into smaller cache sets\n",
    "train_dataset.new_epoch()\n",
    "\n",
    "# creates triplets on the smaller cache set\n",
    "# train_dataset.update_subcache()\n",
    "train_dataset.update_subcache(model, 512)\n",
    "\n",
    "print(len(train_dataset.triplets))\n",
    "print(train_dataset.triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loader\n",
    "opt = {'batch_size': 16, 'shuffle': True, 'collate_fn': CVACTDataset.collate_fn}\n",
    "training_loader = DataLoader(train_dataset, **opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def denormalize(im):\n",
    "\timage = im.numpy()\n",
    "\tim = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "\tim = np.ascontiguousarray(im * 255, dtype=np.uint8)\n",
    "\treturn im\n",
    "\n",
    "def visualize_triplet(batch, sample_idx):\n",
    "\n",
    "\tquery, negatives, meta = batch\n",
    "\tnegCounts, indices, keys = meta['negCounts'], meta['indices'], meta['keys']\n",
    "\n",
    "\tB = query[0].shape[0]\n",
    "\n",
    "\tnum_ns = negCounts[sample_idx].item()\n",
    "\tnum_qns = num_ns + 1\n",
    "\n",
    "\tneg_start = 0\n",
    "\tstart = 0\n",
    "\tif sample_idx > 0: \n",
    "\t\tneg_start = negCounts[:sample_idx].sum().item()\n",
    "\t\tstart = neg_start + sample_idx * 1\n",
    "\t# print(sample_idx, start)\n",
    "\n",
    "\tfig, axes = plt.subplots(nrows=num_qns, ncols=2, figsize=(15,9))\n",
    "\tfig.suptitle(\n",
    "\t\tf'Navigate dataloader of CVACT: current batch, sample {sample_idx} (1 query and {num_ns} negatives)',\n",
    "\t\tfontsize=15)\n",
    "\tfig.tight_layout()\n",
    "\tfig.subplots_adjust(top=0.9)\n",
    "\t\n",
    "\taxes[0,0].imshow(np.transpose(denormalize(query[0][sample_idx]),(1,2,0)))\n",
    "\taxes[0,0].set_title(\n",
    "\t\tf\"Query ==> ground image\\nidx: {indices[start]}, file name: {keys[sample_idx]['query']['gr_img']}\")\n",
    "\n",
    "\taxes[0,1].imshow(np.transpose(denormalize(query[1][sample_idx]),(1,2,0)))\n",
    "\taxes[0,1].set_title(\n",
    "\t\tf\"Query ==> satellite image\\nidx: {indices[start]}, file name: {keys[sample_idx]['query']['sa_img']}\")\n",
    "\n",
    "\t# axes[1,0].imshow(np.transpose(denormalize(positive[0][sample_idx]),(1,2,0)))\n",
    "\t# axes[1,0].set_title(\n",
    "\t# \tf\"Positive ==> ground image\\n{keys[sample_idx]['positive']['gr_img']}\")\n",
    "\t\n",
    "\t# axes[1,1].imshow(np.transpose(denormalize(positive[1][sample_idx]),(1,2,0)))\n",
    "\t# axes[1,1].set_title(\n",
    "\t# \tf\"Positive ==> satellite image\\n{keys[sample_idx]['positive']['sa_img']}\")\n",
    "\n",
    "\tfor i in range(num_ns):\n",
    "\t\taxes[1+i,0].imshow(np.transpose(denormalize(negatives[0][neg_start+i]),(1,2,0)))\n",
    "\t\taxes[1+i,0].set_title(\n",
    "\t\t\tf\"Negative {i} ==> ground image\\nidx: {indices[start+i+1]}, file name: {keys[sample_idx]['negatives'][i]['gr_img']}\")\n",
    "\n",
    "\t\taxes[1+i,1].imshow(np.transpose(denormalize(negatives[1][neg_start+i]),(1,2,0)))\n",
    "\t\taxes[1+i,1].set_title(\n",
    "\t\t\tf\"Negative {i} ==> satellite image\\nidx: {indices[start+i+1]}, file name: {keys[sample_idx]['negatives'][i]['sa_img']}\")\n",
    "\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6392d47288f044248e833ada0a1ee5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='Next Batch', layout=Layout(width='10%'), style=ButtonStyle()), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize triplets\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "button = widgets.Button(\n",
    "    description='Next Batch',\n",
    "    layout=widgets.Layout(width='10%')\n",
    ")\n",
    "out = widgets.Output()\n",
    "bs = training_loader.batch_size\n",
    "it = iter(training_loader)\n",
    "\n",
    "def on_button_clicked(_):\n",
    "    # \"linking function with output\"\n",
    "    with out:\n",
    "        try:\n",
    "            batch = next(it)\n",
    "        except StopIteration:\n",
    "            print(\"Data loader ran out.\")\n",
    "        clear_output()\n",
    "        # display(f'')\n",
    "        sample_slider = widgets.IntSlider(\n",
    "            value=0, min=0, max=bs-1, step=1, \n",
    "            description='Sample:',\n",
    "            layout=widgets.Layout(width='25%')\n",
    "        )\n",
    "        widgets.interact(lambda sample_idx: visualize_triplet(batch, sample_idx),\n",
    "                         sample_idx=sample_slider)\n",
    "button.on_click(on_button_clicked)\n",
    "# displaying button and its output together\n",
    "widgets.VBox([button,out])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look up VGG16 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "enc = models.vgg16(pretrained=True)\n",
    "print(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = list(enc.features.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(layers))\n",
    "for layer in layers[:-5]:\n",
    "    print(layer)\n",
    "    for p in layer.parameters():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /home/jianfengcui/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3856499e237646d685e2f8fa04a69bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "enc = models.resnet50(pretrained=True)\n",
    "layers = list(enc.children())\n",
    "print(len(layers))\n",
    "for layer in layers:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "layers = list(enc.children())[:-2]\n",
    "backbone = nn.Sequential(*layers)\n",
    "im = torch.rand(1, 3, 448, 448)\n",
    "fmp = backbone(im)\n",
    "print(fmp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model and summarywriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May03-1816_cvm_vgg16_max_shared_cvact_5k \t\t 0.6815\n",
      "May01-2242_cvm_vgg16_safa_shared_cvact_5k \t\t 0.847\n",
      "May03-2019_cvm_vgg16_max_noshared_cvact_1k \t\t 0.274\n",
      "May03-0045_simsiam_vgg16_max_shared_cvact_mini \t\t -1.7663664247492235\n",
      "May01-2233_simsiam_vgg16_max_satellite_cvact_mini \t\t -0.9577470079814787\n",
      "May03-2108_oripred_identity_identity_shared_cvact_1k \t\t 0\n",
      "May03-2126_oripred_vgg16_max_shared_cvact_1k \t\t 0\n",
      "May01-2242_cvm_vgg16_safa_noshared_cvact_5k \t\t 0.758\n",
      "May02-0042_cvm_vit_identity_noshared_cvact_5k \t\t 0.0035\n",
      "May03-1943_cvm_vgg16_max_shared_cvact_1k \t\t 0.56\n",
      "May03-2053_oripred_resnet18_identity_shared_cvact_1k \t\t 0\n",
      "May01-2206_cvm_vgg16_max_shared_cvact_5k \t\t 0.718\n",
      "May01-2219_cvm_vgg16_max_noshared_cvact_5k \t\t 0.7065\n",
      "May01-2233_simsiam_vgg16_max_ground_cvact_mini \t\t -0.9095116543898479\n",
      "May02-2156_cvm_vgg16_max_noshared_cvact_5k \t\t 0.6375\n",
      "May03-1745_cvm_resnet18_max_shared_cvact_5k \t\t 0.1165\n",
      "May03-0159_simsiam_vgg16_safa_shared_cvact_mini \t\t -1.8826354594110586\n",
      "May03-1944_cvm_vgg16_max_shared_cvact_1k \t\t 0.5\n",
      "May02-0038_cvm_vit_identity_shared_cvact_5k \t\t 0.1535\n",
      "May03-0157_simsiam_vgg16_max_shared_cvact_full \t\t -1.7561954945854887\n",
      "May03-2033_cvm_vgg16_max_shared_cvact_1k \t\t 0.536\n",
      "May03-1758_cvm_resnet50_max_shared_cvact_5k \t\t 0.0345\n",
      "May03-2008_cvm_vgg16_max_noshared_cvact_1k \t\t 0.45\n",
      "May03-1234_cvm_vgg16_safa_shared_cvact_5k \t\t 0.798\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "from glob import glob\n",
    "for path in glob(\"work_dirs/*\"):\n",
    "    checkpoint = torch.load(path + '/checkpoints/checkpoint.pth.tar', map_location=lambda storage, loc: storage)\n",
    "    print(path.split('/')[1], '\\t\\t', checkpoint['best_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'state_dict', 'best_score', 'not_improved', 'optimizer', 'parallel'])\n",
      "odict_keys(['backbone.0.weight', 'backbone.0.bias', 'backbone.2.weight', 'backbone.2.bias', 'backbone.5.weight', 'backbone.5.bias', 'backbone.7.weight', 'backbone.7.bias', 'backbone.10.weight', 'backbone.10.bias', 'backbone.12.weight', 'backbone.12.bias', 'backbone.14.weight', 'backbone.14.bias', 'backbone.17.weight', 'backbone.17.bias', 'backbone.19.weight', 'backbone.19.bias', 'backbone.21.weight', 'backbone.21.bias', 'backbone.24.weight', 'backbone.24.bias', 'backbone.26.weight', 'backbone.26.bias', 'backbone.28.weight', 'backbone.28.bias', 'projector.layer1.0.weight', 'projector.layer1.0.bias', 'projector.layer1.1.weight', 'projector.layer1.1.bias', 'projector.layer1.1.running_mean', 'projector.layer1.1.running_var', 'projector.layer1.1.num_batches_tracked', 'projector.layer2.0.weight', 'projector.layer2.0.bias', 'projector.layer2.1.weight', 'projector.layer2.1.bias', 'projector.layer2.1.running_mean', 'projector.layer2.1.running_var', 'projector.layer2.1.num_batches_tracked', 'projector.layer3.0.weight', 'projector.layer3.0.bias', 'projector.layer3.1.weight', 'projector.layer3.1.bias', 'projector.layer3.1.running_mean', 'projector.layer3.1.running_var', 'projector.layer3.1.num_batches_tracked', 'predictor.layer1.0.weight', 'predictor.layer1.0.bias', 'predictor.layer1.1.weight', 'predictor.layer1.1.bias', 'predictor.layer1.1.running_mean', 'predictor.layer1.1.running_var', 'predictor.layer1.1.num_batches_tracked', 'predictor.layer2.weight', 'predictor.layer2.bias'])\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('work_dirs/Apr28_21-47-32_simsiam_vgg16_max_cvact_ground/checkpoints/checkpoint.pth.tar', map_location=lambda storage, loc: storage)\n",
    "print(checkpoint.keys())\n",
    "print(checkpoint['state_dict'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Config file\n",
      "num of cuda device: 1\n",
      "current cuda device: 0\n",
      "===> Building model\n",
      "===> Loading model\n",
      "===> Model\n",
      "SAFAvgg16Cls(\n",
      "  (SAFAvgg16): SAFAvgg16(\n",
      "    (nn_model_gr): Module(\n",
      "      (encoder): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (8): ReLU(inplace=True)\n",
      "        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (11): ReLU(inplace=True)\n",
      "        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (13): ReLU(inplace=True)\n",
      "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (15): ReLU(inplace=True)\n",
      "        (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (18): ReLU(inplace=True)\n",
      "        (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (20): ReLU(inplace=True)\n",
      "        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (22): ReLU(inplace=True)\n",
      "        (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (25): ReLU(inplace=True)\n",
      "        (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (27): ReLU(inplace=True)\n",
      "        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (spe): Module(\n",
      "        (spe_0): SPE(\n",
      "          (pool): AdaptiveMaxPool2d(output_size=(14, 14))\n",
      "          (fc1): Linear(in_features=196, out_features=784, bias=True)\n",
      "          (fc2): Linear(in_features=784, out_features=1568, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (nn_model_sa): Module(\n",
      "      (encoder): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (8): ReLU(inplace=True)\n",
      "        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (11): ReLU(inplace=True)\n",
      "        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (13): ReLU(inplace=True)\n",
      "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (15): ReLU(inplace=True)\n",
      "        (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (18): ReLU(inplace=True)\n",
      "        (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (20): ReLU(inplace=True)\n",
      "        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (22): ReLU(inplace=True)\n",
      "        (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (25): ReLU(inplace=True)\n",
      "        (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (27): ReLU(inplace=True)\n",
      "        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (spe): Module(\n",
      "        (spe_0): SPE(\n",
      "          (pool): AdaptiveMaxPool2d(output_size=(14, 14))\n",
      "          (fc1): Linear(in_features=196, out_features=784, bias=True)\n",
      "          (fc2): Linear(in_features=784, out_features=1568, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=8192, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=36, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import yaml\n",
    "from easydict import EasyDict as edict  \n",
    "import os\n",
    "import random\n",
    "from os.path import join, isfile\n",
    "from os import makedirs\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from orissl_cvm import PACKAGE_ROOT_DIR\n",
    "from orissl_cvm.datasets.cvact_dataset_pre import CVACTDatasetPretrain\n",
    "from orissl_cvm.tools.pretrain_epoch import pretrain_epoch\n",
    "from orissl_cvm.tools.val import val\n",
    "from orissl_cvm.tools import save_checkpoint\n",
    "from orissl_cvm.utils import input_transform\n",
    "from orissl_cvm.datasets.cvact_dataset import CVACTDataset\n",
    "from orissl_cvm.models.safa import SAFAvgg16Cls\n",
    "from orissl_cvm.tools.visualize import visualize_dataloader\n",
    "\n",
    "from tqdm.auto import trange\n",
    "\n",
    "\n",
    "# Load config file\n",
    "cfg_file = \"configs/train.yaml\"\n",
    "assert os.path.isfile(cfg_file)\n",
    "with open(cfg_file, 'r') as f:\n",
    "    config = edict(yaml.load(f, Loader=yaml.Loader))\n",
    "\n",
    "print('===> Config file')\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.train.gpu_ids\n",
    "os.environ[\"MKL_NUM_THREADS\"] = config.train.threads\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = config.train.threads\n",
    "os.environ[\"OMP_NUM_THREADS\"] = config.train.threads\n",
    "\n",
    "# CUDA setting\n",
    "cuda = not config.train.no_cuda\n",
    "if cuda and not torch.cuda.is_available():\n",
    "    raise Exception(\"No GPU found, please run with --nocuda\")\n",
    "\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "print(f'num of cuda device: {torch.cuda.device_count()}')\n",
    "print(f'current cuda device: {torch.cuda.current_device()}')\n",
    "\n",
    "# Random seeds\n",
    "random.seed(config.train.seed)\n",
    "np.random.seed(config.train.seed)\n",
    "torch.manual_seed(config.train.seed)\n",
    "if cuda:\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    torch.cuda.manual_seed(config.train.seed)\n",
    "\n",
    "# Model: with resuming or not\n",
    "print('===> Building model')\n",
    "\n",
    "if config.train.resume_path: # if already started training earlier and continuing\n",
    "    if isfile(config.train.resume_path):\n",
    "        print(\"=> loading checkpoint '{}'\".format(config.train.resume_path))\n",
    "        checkpoint = torch.load(config.train.resume_path, map_location=lambda storage, loc: storage)\n",
    "\n",
    "        model = SAFAvgg16Cls()\n",
    "\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        config.train.start_epoch = checkpoint['epoch']\n",
    "\n",
    "        print(\"=> loaded checkpoint '{}'\".format(config.train.resume_path))\n",
    "    else:\n",
    "        raise FileNotFoundError(\"=> no checkpoint found at '{}'\".format(config.train.resume_path))\n",
    "else: # if not, assume fresh training instance and will initially generate cluster centroids\n",
    "    print('===> Loading model')\n",
    "    model = SAFAvgg16Cls()\n",
    "\n",
    "desc_dim = model.SAFAvgg16.desc_dim\n",
    "print(\"===> Model\")\n",
    "print(model)\n",
    "\n",
    "# If DataParallel\n",
    "# TODO learn more about multi-gpu training. Actually more stuff needs\n",
    "# to be considered, e.g., only log info of local rank 0\n",
    "isParallel = False\n",
    "if config.train.n_gpu > 1 and torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "    isParallel = True\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = None\n",
    "scheduler = None\n",
    "\n",
    "if config.params.optim == 'ADAM':\n",
    "    optimizer = optim.Adam(filter(lambda par: par.requires_grad,\n",
    "                                    model.parameters()), lr=config.params.lr)  # , betas=(0,0.9))\n",
    "elif config.params.optim == 'SGD':\n",
    "    optimizer = optim.SGD(filter(lambda par: par.requires_grad,\n",
    "                                    model.parameters()), lr=config.params.lr,\n",
    "                            momentum=config.params.momentum,\n",
    "                            weight_decay=config.params.weight_decay)\n",
    "\n",
    "    # TODO include scheduler later\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=config.train.lr_step,\n",
    "    #                                       gamma=config.train.lr_gamma)\n",
    "else:\n",
    "    raise ValueError('Unknown optimizer: ' + config.params.optim)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "if config.train.resume_path:\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading dataset(s)\n",
      "Construct neighbor searches for train set: kd_tree\n",
      "Finding positive neighbors for 5404 queries\n",
      "Finding non-negative neighbors for 5404 queries\n",
      "Full num of images in training set: 5404\n",
      "Num of queries in training set: 5404\n"
     ]
    }
   ],
   "source": [
    "# Loss\n",
    "# TODO delete it later, because we're actually using our own loss function\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# Dataset and dataloader\n",
    "print('===> Loading dataset(s)')\n",
    "train_dataset = CVACTDatasetPretrain(config.train.dataset_root_dir, \n",
    "                                    mode='train', \n",
    "                                    transform=input_transform())\n",
    "print(f'Full num of images in training set: {train_dataset.qImages.shape[0]}')\n",
    "print(f'Num of queries in training set: {len(train_dataset)}')\n",
    "\n",
    "training_data_loader = DataLoader(dataset=train_dataset, \n",
    "    num_workers=int(config.train.threads),\n",
    "    batch_size=config.train.batch_size, \n",
    "    shuffle=True,\n",
    "    pin_memory=cuda\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# NOTE visualize batches for debug\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mvisualize_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/zxia/MSc/Jianfeng/projects/orissl-cvm/orissl_cvm/tools/visualize.py:119\u001b[0m, in \u001b[0;36mvisualize_dataloader\u001b[0;34m(training_loader)\u001b[0m\n\u001b[1;32m    115\u001b[0m \tbatch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(it)\n\u001b[1;32m    116\u001b[0m \t\u001b[38;5;66;03m# for i in range(bs):\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \t\u001b[38;5;66;03m# \tvisualize_triplet(batch, i)\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \t\u001b[38;5;66;03m# visualize_plain_batch(batch)\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m \t\u001b[43mvisualize_plain_batch_pretrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m \t\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData loader ran out.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/scratch/zxia/MSc/Jianfeng/projects/orissl-cvm/orissl_cvm/tools/visualize.py:90\u001b[0m, in \u001b[0;36mvisualize_plain_batch_pretrain\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_plain_batch_pretrain\u001b[39m(batch):\n\u001b[0;32m---> 90\u001b[0m \tquery_gr, query_sa, label, meta \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     91\u001b[0m \tindices, keys \u001b[38;5;241m=\u001b[39m meta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindices\u001b[39m\u001b[38;5;124m'\u001b[39m], meta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeys\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     92\u001b[0m \tB \u001b[38;5;241m=\u001b[39m query_gr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "# NOTE visualize batches for debug\n",
    "visualize_dataloader(training_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.]), array([0.])]\n",
      "[array([1.]), array([1.])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a1 = [np.zeros(1)]\n",
    "a2 = a1 * 2\n",
    "b1 = [np.ones(1)]\n",
    "b2 = b1 * 2\n",
    "\n",
    "print(a2)\n",
    "print(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.]), array([0.])] token3\n",
      "[array([1.]), array([1.])] token4\n",
      "[array([0.])] token3\n",
      "[array([0.]), array([0.])] token4\n"
     ]
    }
   ],
   "source": [
    "c = 'token3'\n",
    "d = 'token4'\n",
    "for x, y in zip([a2, b2], [c, d]):\n",
    "    print(x, y)\n",
    "for x, y in zip([a1, a2, b1, b2], [c, d]):\n",
    "    print(x, y)\n",
    "# 直观来说，zip起来直接一起iterate更方便"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A a 1\n",
      "B b 2\n",
      "C c 3\n"
     ]
    }
   ],
   "source": [
    "uppercase = ['A', 'B', 'C']\n",
    "lowercase = ['a', 'b', 'c']\n",
    "numbers = [1, 2, 3]\n",
    "\n",
    "for x, y, z in zip(uppercase, lowercase, numbers):\n",
    "    print(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(2, 0), dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "a[..., :0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horizontal_correlation(fmp1, fmp2):\n",
    "    B, C, H = fmp1.shape[:3]\n",
    "    print(B, C, H)\n",
    "    W1, W2 = fmp1.shape[3], fmp2.shape[3]\n",
    "    fmp2 = torch.cat([fmp2, fmp2[..., :(W1 - 1)]], dim=-1)\n",
    "    resp = torch.empty((B, 1, 1, W2))\n",
    "    # NOTE the batch dim of the kernel fmp will serve as the num of kernels.\n",
    "    # so now do it separately\n",
    "    for i in range(B):\n",
    "        resp[i:i+1] = F.conv2d(fmp2[i:i+1], fmp1[i:i+1], bias=None, stride=1, padding=0)\n",
    "    resp = resp.flatten(start_dim=-3, end_dim=-1)\n",
    "    _, resp = torch.max(resp, dim=1, keepdim=True)\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 2\n",
      "tensor([[0]])\n",
      "1 1 2\n",
      "tensor([[1]])\n",
      "1 1 2\n",
      "tensor([[2]])\n",
      "1 1 2\n",
      "tensor([[3]])\n",
      "1 1 2\n",
      "tensor([[2]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "a = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]], dtype=float)\n",
    "b = torch.tensor([[2, 3, 4, 1], [6, 7, 8, 5]], dtype=float)\n",
    "c = torch.tensor([[3, 4, 1, 2], [7, 8, 5, 6]], dtype=float)\n",
    "d = torch.tensor([[4, 1, 2, 3], [8, 5, 6, 7]], dtype=float)\n",
    "a = a[None, None, ...]\n",
    "b = b[None, None, ...]\n",
    "c = c[None, None, ...]\n",
    "d = d[None, None, ...]\n",
    "print(horizontal_correlation(a, a))\n",
    "print(horizontal_correlation(b, a))\n",
    "print(horizontal_correlation(c, a))\n",
    "print(horizontal_correlation(d, a))\n",
    "print(horizontal_correlation(d, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "302881b9d586535b3239efc069d02e6e93f6502ee2b8ffca8a2c5ae3d135ae98"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('vissl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
