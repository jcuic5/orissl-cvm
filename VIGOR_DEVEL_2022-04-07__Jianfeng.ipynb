{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIGOR Development Notebook\n",
    "\n",
    "Author: Ted de Vries Lentsch\n",
    "\n",
    "First version on March 24, 2022\n",
    "\n",
    "Last update on April 7, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code settings\n",
    "DO_INTERACTION        = False                                                           # widgets and plots\n",
    "DO_LOCAL              = False                                                           # run code on local machine\n",
    "\n",
    "# VIGOR dataset (be careful!)\n",
    "DO_RESIZE             = False                                                           # load, resize, and save VIGOR dataset\n",
    "DO_NEW_YORK_ONLY      = True                                                            # use only the city New York\n",
    "DO_DATA_AUGMENTATION  = False                                                           # use data augmentation for training\n",
    "DO_FULL_DATASET       = False                                                           # use all New York image pairs\n",
    "DO_POS_ONLY           = False                                                           # use only the positive satellite images\n",
    "\n",
    "# train settings\n",
    "CUSTOM_DATASET_LENGTH = 10                                                              # custom train dataset length\n",
    "BATCH_SIZE            = 8                                                               # batch size\n",
    "ADD_RELU              = False                                                           # relu activation for first layer\n",
    "ADD_SIGMOID           = False                                                           # sigmoid activation for second layer\n",
    "\n",
    "# train and test\n",
    "DO_TRAIN              = False                                                           # train the model\n",
    "DO_TEST               = False                                                           # test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_INTERACTION:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]    = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"                                                # GPU index\n",
    "os.environ[\"MKL_NUM_THREADS\"]      = \"6\"                                                # num of threads\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"]  = \"6\"                                                # num of threads\n",
    "os.environ[\"OMP_NUM_THREADS\"]      = \"6\"                                                # num of threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# PyTorch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as th_data\n",
    "import torchvision as th_vision\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# widgets\n",
    "if DO_INTERACTION:\n",
    "    import ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = th.device(\"cuda:0\" if th.cuda.is_available() else \"cpu\")\n",
    "\"The device is: {}\".format(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Visualize Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Folder names\n",
    "if DO_NEW_YORK_ONLY:\n",
    "    vigor_cities = [\"NewYork\"]\n",
    "else:\n",
    "    vigor_cities           = [\"Chicago\",\"NewYork\",\"SanFrancisco\",\"Seattle\"]\n",
    "vigor_files            = [\"pano_label_balanced.txt\", \"same_area_balanced_train.txt\", \"same_area_balanced_test.txt\"]\n",
    "streetfolder_name      = \"panorama\"\n",
    "satellitefolder_name   = \"satellite\"\n",
    "combinationfolder_name = \"splits\"\n",
    "\n",
    "\n",
    "# Directories\n",
    "if DO_LOCAL:\n",
    "    notebookfolder_dir = os.getcwd()\n",
    "    root_dir           = os.path.dirname(os.path.dirname(notebookfolder_dir))\n",
    "else:\n",
    "    assert False, \"Change this directory!\"\n",
    "    root_dir = os.path.join(\"CHANGE\")\n",
    "vigor_dir   = os.path.join(\"datasets\", \"VIGOR\")\n",
    "dataset_dir = os.path.join(root_dir, vigor_dir)\n",
    "\n",
    "\n",
    "# Count function\n",
    "def count_num_img(dataset_dir, city_name, streetfolder_name, satellitefolder_name):\n",
    "    street_dir = os.path.join(dataset_dir, city_name, streetfolder_name)\n",
    "    satellite_dir = os.path.join(dataset_dir, city_name, satellitefolder_name)\n",
    "    \n",
    "    num_street_img = len(list(sorted(os.listdir(street_dir))))\n",
    "    num_satellite_img = len(list(sorted(os.listdir(satellite_dir))))\n",
    "    \n",
    "    print(f\"\\n{city_name} has {num_street_img} street and {num_satellite_img} satellite images!\")\n",
    "\n",
    "\n",
    "# Widget\n",
    "if DO_INTERACTION:\n",
    "    ipywidgets.interact(lambda city: count_num_img(dataset_dir=dataset_dir,\n",
    "                                                  city_name=city,\n",
    "                                                  streetfolder_name=streetfolder_name,\n",
    "                                                  satellitefolder_name=satellitefolder_name),\n",
    "                        city=vigor_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Show Image Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot function\n",
    "def plot_img(dataset_dir, city_name, streetfolder_name, satellitefolder_name, combinationfolder_name, file, idx):\n",
    "    \"\"\" Plot a street image and accompanying satellite images in one figure. \"\"\"\n",
    "    \n",
    "    def get_img_names_and_deltas(file_dir, idx):\n",
    "        data_list = []\n",
    "        with open(file_dir, 'r') as file:\n",
    "            cnt = 0\n",
    "            for line in file.readlines():\n",
    "                data = line.split(' ')\n",
    "                if cnt==idx:\n",
    "                    data_list.append(data[0])\n",
    "                    for idx in range(4):\n",
    "                        data_list.append((data[3*idx+1], float(data[3*idx+2]), float(data[3*idx+3])))\n",
    "                    break\n",
    "                else:\n",
    "                    cnt +=1\n",
    "        return data_list\n",
    "    \n",
    "    # directories\n",
    "    street_dir = os.path.join(dataset_dir, city_name, streetfolder_name)\n",
    "    satellite_dir = os.path.join(dataset_dir, city_name, satellitefolder_name)\n",
    "    file_dir = os.path.join(dataset_dir, combinationfolder_name, city_name, file)\n",
    "    \n",
    "    # data\n",
    "    data_list = get_img_names_and_deltas(file_dir, idx)\n",
    "    street_img = cv2.imread(os.path.join(street_dir, data_list[0]))[:,:,::-1]\n",
    "    satellite_img1 = cv2.imread(os.path.join(satellite_dir, data_list[1][0]))[:,:,::-1]\n",
    "    satellite_img2 = cv2.imread(os.path.join(satellite_dir, data_list[2][0]))[:,:,::-1]\n",
    "    satellite_img3 = cv2.imread(os.path.join(satellite_dir, data_list[3][0]))[:,:,::-1]\n",
    "    satellite_img4 = cv2.imread(os.path.join(satellite_dir, data_list[4][0]))[:,:,::-1]\n",
    "    delta1, delta2, delta3, delta4 = data_list[1][1:], data_list[2][1:], data_list[3][1:], data_list[4][1:]\n",
    "    W, H, A = street_img.shape[1], street_img.shape[0], satellite_img1.shape[0]\n",
    "\n",
    "    # create plot\n",
    "    fig = plt.figure(figsize=[15, 11])\n",
    "    grid = plt.GridSpec(2, 3, wspace=0.2, hspace=0.2)\n",
    "    ax1 = plt.subplot(grid[0, :2])\n",
    "    ax2 = plt.subplot(grid[0, 2])\n",
    "    ax3 = plt.subplot(grid[1, 0])\n",
    "    ax4 = plt.subplot(grid[1, 1])\n",
    "    ax5 = plt.subplot(grid[1, 2])\n",
    "    \n",
    "    # plot street view\n",
    "    ax1.imshow(street_img, extent=(0, W, H, 0), zorder=-10)\n",
    "    ax1.set_title('Street View', pad=10, fontsize=24)\n",
    "    ax1.set_xlim(0, W)\n",
    "    ax1.set_ylim(H, 0)\n",
    "    \n",
    "    # plot satellite view\n",
    "    axs = [ax2, ax3, ax4, ax5]\n",
    "    titles = [\"Satellite View (Positive)\", \"Semi-Positive 1\", \"Semi-Positive 2\", \"Semi-Positive 3\"]\n",
    "    imgs = [satellite_img1, satellite_img2, satellite_img3, satellite_img4]\n",
    "    for ax, title, img in zip(axs, titles, imgs):\n",
    "        ax.imshow(img, extent=(0, A, A, 0), zorder=-10)\n",
    "        ax.set_title(title, pad=16, fontsize=24)\n",
    "        ax.set_xlim(0, A)\n",
    "        ax.set_ylim(A, 0)\n",
    "    \n",
    "    # plot rays\n",
    "    colors = ['springgreen', 'deepskyblue', 'orange', 'magenta'] # North, East, South, West\n",
    "    \n",
    "    ax1.vlines(x=0.00*W, ymin=0, ymax=H, color=colors[2], linewidth=3, zorder=10) # South\n",
    "    ax1.vlines(x=0.25*W, ymin=0, ymax=H, color=colors[3], linewidth=3, zorder=10) # West\n",
    "    ax1.vlines(x=0.50*W, ymin=0, ymax=H, color=colors[0], linewidth=3, zorder=10) # North\n",
    "    ax1.vlines(x=0.75*W, ymin=0, ymax=H, color=colors[1], linewidth=3, zorder=10) # East\n",
    "    ax1.vlines(x=1.00*W, ymin=0, ymax=H, color=colors[2], linewidth=3, zorder=10) # South\n",
    "\n",
    "    deltas = [delta1, delta2, delta3, delta4]\n",
    "    for ax, delta in zip(axs, deltas):\n",
    "        xc, yc = A/2-A/640*delta[1], A/2+A/640*delta[0] # see GitHub of VIGOR for this formula\n",
    "        ax.scatter(xc, yc, s=150, color=\"yellow\", zorder=20) # Center\n",
    "        ax.vlines(x=xc, ymin=0, ymax=yc, color=colors[0], linewidth=3, zorder=10) # North\n",
    "        ax.hlines(y=yc, xmin=xc, xmax=A, color=colors[1], linewidth=3, zorder=10) # East\n",
    "        ax.vlines(x=xc, ymin=yc, ymax=A, color=colors[2], linewidth=3, zorder=10) # South\n",
    "        ax.hlines(y=yc, xmin=0, xmax=xc, color=colors[3], linewidth=3, zorder=10) # West\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    # print image names\n",
    "    print(\"Street view:                      {}\".format(data_list[0]))\n",
    "    print(\"Satellite view (positive):        {}\".format(data_list[1][0]))\n",
    "    print(\"Satellite view (semi-positive 1): {}\".format(data_list[2][0]))\n",
    "    print(\"Satellite view (semi-positive 2): {}\".format(data_list[3][0]))\n",
    "    print(\"Satellite view (semi-positive 3): {}\".format(data_list[4][0]))\n",
    "\n",
    "\n",
    "# Widget\n",
    "if DO_INTERACTION:\n",
    "    ipywidgets.interact(lambda city, file, idx: plot_img(dataset_dir=dataset_dir,\n",
    "                                                         city_name=city,\n",
    "                                                         streetfolder_name=streetfolder_name,\n",
    "                                                         satellitefolder_name=satellitefolder_name,\n",
    "                                                         combinationfolder_name=combinationfolder_name,\n",
    "                                                         file=file,\n",
    "                                                         idx=idx),\n",
    "                        city=vigor_cities,\n",
    "                        file=vigor_files,\n",
    "                        idx=range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Resize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_RESIZE:\n",
    "    street_height_resized    = 320\n",
    "    street_width_resized     = 640\n",
    "    satellite_height_resized = 512\n",
    "    satellite_width_resized  = 512\n",
    "\n",
    "    if DO_NEW_YORK_ONLY:\n",
    "        vigor_cities = [\"NewYork\"]\n",
    "        vigor_files  = [\"same_area_balanced_train.txt\",\"same_area_balanced_test.txt\"]\n",
    "    else:\n",
    "        vigor_cities = [\"Chicago\",\"NewYork\",\"SanFrancisco\",\"Seattle\"]\n",
    "        vigor_files  = [\"pano_label_balanced.txt\",\"same_area_balanced_train.txt\",\"same_area_balanced_test.txt\"]\n",
    "        \n",
    "    for city_name in vigor_cities:\n",
    "        street_name_list, satellite_name_list = [], []\n",
    "\n",
    "        # folders with original images\n",
    "        streetfolder_dir    = os.path.join(dataset_dir, city_name, streetfolder_name)\n",
    "        satellitefolder_dir = os.path.join(dataset_dir, city_name, satellitefolder_name)\n",
    "\n",
    "        # folders with resized images\n",
    "        streetfolder_resized_dir    = os.path.join(dataset_dir, city_name, streetfolder_name)+\"_resized\"\n",
    "        satellitefolder_resized_dir = os.path.join(dataset_dir, city_name, satellitefolder_name)+\"_resized\"\n",
    "\n",
    "        # make folders\n",
    "        if os.path.isdir(streetfolder_resized_dir):\n",
    "            shutil.rmtree(streetfolder_resized_dir)\n",
    "            time.sleep(0.1)\n",
    "        if os.path.isdir(satellitefolder_resized_dir):\n",
    "            shutil.rmtree(satellitefolder_resized_dir)\n",
    "            time.sleep(0.1)    \n",
    "        os.makedirs(streetfolder_resized_dir)\n",
    "        os.makedirs(satellitefolder_resized_dir)\n",
    "\n",
    "        # read images, resized, and save to new directory\n",
    "        for file_name in vigor_files:\n",
    "            file_dir = os.path.join(dataset_dir, combinationfolder_name, city_name, file_name)\n",
    "            with open(file_dir, 'r') as file:\n",
    "                for line in file.readlines():\n",
    "                    data = line.split(' ')\n",
    "                    street_img_name = data[0]\n",
    "                    satellite_img_names = [data[1], data[4], data[7], data[10]]\n",
    "\n",
    "                    # street image\n",
    "                    if street_img_name not in street_name_list:\n",
    "                        street_name_list.append(street_img_name)\n",
    "\n",
    "                        # image directories\n",
    "                        street_img_dir = os.path.join(streetfolder_dir, street_img_name)\n",
    "                        street_resized_img_dir = os.path.join(streetfolder_resized_dir, street_img_name)\n",
    "\n",
    "                        # read, resized and save image\n",
    "                        street_img = cv2.imread(street_img_dir)\n",
    "                        street_resized_img = cv2.resize(src=street_img,\n",
    "                                                        dsize=(street_width_resized, street_height_resized),\n",
    "                                                        interpolation=cv2.INTER_AREA)\n",
    "                        cv2.imwrite(filename=street_resized_img_dir, img=street_resized_img)\n",
    "\n",
    "                    # satellite image\n",
    "                    for satellite_img_name in satellite_img_names:\n",
    "                        if satellite_img_name not in satellite_name_list:\n",
    "                            satellite_name_list.append(satellite_img_name)\n",
    "\n",
    "                            # image directories\n",
    "                            satellite_img_dir = os.path.join(satellitefolder_dir, satellite_img_name)\n",
    "                            satellite_resized_img_dir = os.path.join(satellitefolder_resized_dir, satellite_img_name)\n",
    "\n",
    "                            # read, resized and save image\n",
    "                            satellite_img = cv2.imread(satellite_img_dir)\n",
    "                            satellite_resized_img = cv2.resize(src=satellite_img,\n",
    "                                                               dsize=(satellite_width_resized, satellite_height_resized),\n",
    "                                                               interpolation=cv2.INTER_AREA)\n",
    "                            cv2.imwrite(filename=satellite_resized_img_dir, img=satellite_resized_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Show Resized Image Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# folder names\n",
    "streetfolder_resized_name = streetfolder_name+\"_resized\"\n",
    "satellitefolder_resized_name = satellitefolder_name+\"_resized\"\n",
    "\n",
    "\n",
    "# cities and files\n",
    "if DO_NEW_YORK_ONLY:\n",
    "    vigor_cities = [\"NewYork\"]\n",
    "    vigor_files  = [\"same_area_balanced_train.txt\",\"same_area_balanced_test.txt\"]\n",
    "else:\n",
    "    vigor_cities = [\"Chicago\",\"NewYork\",\"SanFrancisco\",\"Seattle\"]\n",
    "    vigor_files  = [\"pano_label_balanced.txt\",\"same_area_balanced_train.txt\",\"same_area_balanced_test.txt\"]\n",
    "\n",
    "\n",
    "# widget\n",
    "if DO_INTERACTION:\n",
    "    ipywidgets.interact(lambda city, file, idx: plot_img(dataset_dir=dataset_dir,\n",
    "                                                         city_name=city,\n",
    "                                                         streetfolder_name=streetfolder_resized_name,\n",
    "                                                         satellitefolder_name=satellitefolder_resized_name,\n",
    "                                                         combinationfolder_name=combinationfolder_name,\n",
    "                                                         file=file,\n",
    "                                                         idx=idx),\n",
    "                        city=vigor_cities,\n",
    "                        file=vigor_files,\n",
    "                        idx=range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class VIGORDataset(th_data.Dataset):\n",
    "    \"\"\" VIGOR dataset class. \"\"\"\n",
    "    \n",
    "    def __init__(self, root, cities, streetfolder_name, satellitefolder_name, combinationfolder_name, file_name,\n",
    "                 transforms=None, only_pos=False):\n",
    "        self.root       = root                                                          # directory to dataset\n",
    "        self.cities     = cities                                                        # list with cities\n",
    "        self.transforms = transforms                                                    # list with transforms\n",
    "        \n",
    "        # (resized) images dimensions\n",
    "        self.H            = 320                                                         # height of street image\n",
    "        self.W            = 640                                                         # width of street image\n",
    "        self.A            = 512                                                         # height and width of satellite image\n",
    "        self.A_original   = 640                                                         # height and width of satellite image\n",
    "        self.scale_factor = self.A/self.A_original                                      # new_size/old_size satellite image\n",
    "        \n",
    "        # get combinations\n",
    "        self.combs      = []                                                            # (street, satellite) combinations\n",
    "        self.annots     = []                                                            # deltas\n",
    "        self.get_combinations(streetfolder_name, satellitefolder_name, combinationfolder_name, file_name, only_pos)\n",
    "\n",
    "    def get_combinations(self, streetfolder_name, satellitefolder_name, combinationfolder_name, file_name, only_pos):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            streetfolder_name (str):      name of folder with street images\n",
    "            satellitefolder_name (str):   name of folder with satellite images\n",
    "            combinationfolder_name (str): name of folder with combination and splits information\n",
    "            file_name (str):              name of (text) document with combination information\n",
    "        \"\"\"\n",
    "        \n",
    "        for city_name in self.cities:\n",
    "            file_dir = os.path.join(self.root, combinationfolder_name, city_name, file_name)\n",
    "            with open(file_dir, 'r') as file:\n",
    "                for line in file.readlines():\n",
    "                    data = line.split(' ')\n",
    "                    street_img_subdir = os.path.join(city_name, streetfolder_name, data[0])\n",
    "                    for idx in range(4):\n",
    "                        satellite_img_subdir = os.path.join(city_name, satellitefolder_name, data[3*idx+1])\n",
    "                        delta = (float(data[3*idx+2]), float(data[3*idx+3]))\n",
    "                        if abs(delta[0])<=self.A//2 and abs(delta[1])<=self.A//2: # check whether GT location is on image\n",
    "                            self.combs.append((street_img_subdir, satellite_img_subdir))\n",
    "                            self.annots.append((self.A//2+self.scale_factor*delta[0], self.A//2-self.scale_factor*delta[1]))\n",
    "                        if only_pos:\n",
    "                            break\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            idx (int): index of sample\n",
    "        Output:\n",
    "            imgs (list):   list with street and satellite image (both tensors)\n",
    "            target (dict): dict with index of sample and annotation (the GT location) \n",
    "        \"\"\"\n",
    "        \n",
    "        street_img_dir    = os.path.join(self.root, self.combs[idx][0])\n",
    "        satellite_img_dir = os.path.join(self.root, self.combs[idx][1])\n",
    "        \n",
    "        street_img    = cv2.imread(street_img_dir)[:,:,::-1]\n",
    "        satellite_img = cv2.imread(satellite_img_dir)[:,:,::-1]\n",
    "        imgs          = [street_img, satellite_img]\n",
    "\n",
    "        target                 = {}                                                     # target\n",
    "        target['image_id']     = th.tensor([idx])                                       # image id (equal to index)\n",
    "        target['street_id']    = self.combs[idx][0]                                     # subdir of street image\n",
    "        target['satellite_id'] = self.combs[idx][1]                                     # subdir of satellite image\n",
    "        target['location']     = th.tensor([*self.annots[idx]])                         # location (h, w)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            imgs, target = self.transforms(imgs, target)\n",
    "\n",
    "        return imgs, target\n",
    "\n",
    "    def __len__(self):       \n",
    "        return len(self.combs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Define transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\" Convert all images in the list to tensors with type float. \"\"\"\n",
    "    \n",
    "    def __call__(self, imgs, target):\n",
    "        imgs = [F.to_tensor(img.copy()).type(th.float) for img in imgs]\n",
    "      \n",
    "        return imgs, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class NormalizeTensor(object):\n",
    "    \"\"\" Normalize tensors by using PyTorch ImageNet mean and std. \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.mean = [0.485, 0.456, 0.406]\n",
    "        self.std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    def __call__(self, imgs, target):\n",
    "        imgs = [F.normalize(img, self.mean, self.std) for img in imgs]\n",
    "        \n",
    "        return imgs, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomRotateSatellite(object):\n",
    "    \"\"\" Rotate the satellite image 0, 90, 180 or 270 degrees randomly. \"\"\"\n",
    "\n",
    "    def __init__(self, W, A):\n",
    "        self.prob_thresholds = [0.25, 0.50, 0.75, 1.00]\n",
    "        self.W               = W\n",
    "        self.A               = A\n",
    "\n",
    "    def __call__(self, imgs, target, prob=random.random()):       \n",
    "        # no rotation\n",
    "        if prob<=self.prob_thresholds[0]:\n",
    "            return imgs, target\n",
    "        else:\n",
    "            street_img, satellite_img = imgs\n",
    "            location                  = target[\"location\"]\n",
    "\n",
    "            # 90 degrees rotation\n",
    "            if prob<=self.prob_thresholds[1]:\n",
    "                satellite_img = th.rot90(satellite_img, 1, [-1,-2])                     # rotate 90 degrees clockwise\n",
    "                part1 = street_img[:,:,int(0.00*self.W):int(0.25*self.W)]               # part1\n",
    "                part2 = street_img[:,:,int(0.25*self.W):int(0.50*self.W)]               # part2\n",
    "                part3 = street_img[:,:,int(0.50*self.W):int(0.75*self.W)]               # part3\n",
    "                part4 = street_img[:,:,int(0.75*self.W):int(1.00*self.W)]               # part4\n",
    "                street_img    = th.cat((part4, part1, part2, part3), dim=2)             # combine all parts\n",
    "                location      = th.tensor([location[1], self.A-location[0]])            # change location\n",
    "            # 180 degrees rotation\n",
    "            elif prob<=self.prob_thresholds[2]:\n",
    "                satellite_img = th.rot90(satellite_img, 2, [-1,-2])                     # rotate 180 degrees clockwise\n",
    "                part1 = street_img[:,:,int(0.00*self.W):int(0.25*self.W)]               # part1\n",
    "                part2 = street_img[:,:,int(0.25*self.W):int(0.50*self.W)]               # part2\n",
    "                part3 = street_img[:,:,int(0.50*self.W):int(0.75*self.W)]               # part3\n",
    "                part4 = street_img[:,:,int(0.75*self.W):int(1.00*self.W)]               # part4\n",
    "                street_img    = th.cat((part3, part4, part1, part2), dim=2)             # combine all parts\n",
    "                location      = th.tensor([self.A-location[0], self.A-location[1]])     # change location\n",
    "            # 270 degrees rotation\n",
    "            elif prob<=self.prob_thresholds[3]:\n",
    "                satellite_img = th.rot90(satellite_img, 3, [-1,-2])                     # rotate 270 degrees clockwise\n",
    "                part1 = street_img[:,:,int(0.00*self.W):int(0.25*self.W)]               # part1\n",
    "                part2 = street_img[:,:,int(0.25*self.W):int(0.50*self.W)]               # part2\n",
    "                part3 = street_img[:,:,int(0.50*self.W):int(0.75*self.W)]               # part3\n",
    "                part4 = street_img[:,:,int(0.75*self.W):int(1.00*self.W)]               # part4\n",
    "                street_img    = th.cat((part2, part3, part4, part1), dim=2)             # combine all parts\n",
    "                location      = th.tensor([self.A-location[1], location[0]])            # change location\n",
    "\n",
    "            imgs                     = [street_img, satellite_img]\n",
    "            target[\"location\"]       = location\n",
    "            target[\"Rotated\"] = 1\n",
    "            \n",
    "            return imgs, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class RandomHorizontalFlipSatellite(object):\n",
    "    \"\"\" Flip the satellite image horizontally with a certain probability. \"\"\"\n",
    "    \n",
    "    def __init__(self, A):\n",
    "        self.prob_threshold = 0.5\n",
    "        self.A              = A\n",
    "\n",
    "    def __call__(self, imgs, target):\n",
    "        if random.random()<=self.prob_threshold:\n",
    "            street_img, satellite_img = imgs\n",
    "            location                  = target[\"location\"]\n",
    "            \n",
    "            satellite_img = satellite_img.flip([2])                                     # flip satellite image horizontally\n",
    "            street_img    = street_img.flip([2])                                        # flip satellite image horizontally\n",
    "            location      = th.tensor([location[0], self.A-location[1]])                # change width location\n",
    "            \n",
    "            imgs                     = [street_img, satellite_img]\n",
    "            target[\"location\"]       = location\n",
    "            target[\"HorizontalFlip\"] = 1\n",
    "\n",
    "        return imgs, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class RandomVerticalFlipSatellite(object):\n",
    "    \"\"\" Flip the satellite image vertically with a certain probability. \"\"\"\n",
    "    \n",
    "    def __init__(self, W, A):\n",
    "        self.prob_threshold = 0.5\n",
    "        self.W              = W\n",
    "        self.A              = A\n",
    "\n",
    "    def __call__(self, imgs, target):\n",
    "        if random.random()<=self.prob_threshold:\n",
    "            street_img, satellite_img = imgs\n",
    "            location                  = target[\"location\"]\n",
    "            \n",
    "            satellite_img = satellite_img.flip([1])                                     # flip satellite image vertically\n",
    "            left_part     = street_img[:,:,:self.W//2].flip([2])                        # flip left part horizontally\n",
    "            right_part    = street_img[:,:,self.W//2:].flip([2])                        # flip right part horizontally\n",
    "            street_img    = th.cat((left_part, right_part), dim=2)                      # combine left and right part\n",
    "            location      = th.tensor([self.A-location[0], location[1]])                # change height location\n",
    "            \n",
    "            imgs                   = [street_img, satellite_img]\n",
    "            target[\"location\"]     = location\n",
    "            target[\"VerticalFlip\"] = 1\n",
    "\n",
    "        return imgs, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Compose(object):\n",
    "    \"\"\" Apply all transformations. \"\"\"\n",
    "    \n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, imgs, target):\n",
    "        for transform in self.transforms:\n",
    "            imgs, target = transform(imgs, target)\n",
    "            \n",
    "        return imgs, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_transform(normalize=True, train=False, rotate=False, hflip=False, vflip=False, H=320, W=640, A=512):\n",
    "    \"\"\" Combine all transformations into a single transformation. \"\"\"\n",
    "    \n",
    "    transforms = []\n",
    "    \n",
    "    # numpy array to tensor (this scales element values from 0-255 to 0-1)\n",
    "    transforms.append(ToTensor())\n",
    "    \n",
    "    # normalize tensor\n",
    "    if normalize:\n",
    "        transforms.append(NormalizeTensor())\n",
    "    \n",
    "    # during training, randomly flip the satellite images and change the street images accordingly\n",
    "    if train:\n",
    "        if rotate:\n",
    "            transforms.append(RandomRotateSatellite(W=W, A=A))\n",
    "        if hflip:\n",
    "            transforms.append(RandomHorizontalFlipSatellite(A=A))\n",
    "        if vflip:\n",
    "            transforms.append(RandomVerticalFlipSatellite(W=W, A=A))\n",
    "\n",
    "    return Compose(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Show Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot function\n",
    "def plot_visual_transforms(dataset, idx, Rotate, HorizontalFlip, VerticalFlip):\n",
    "    \"\"\" Plot a street image and accompanying satellite images in one figure. \"\"\"\n",
    "\n",
    "    visual_transforms = [RandomRotateSatellite(W=640, A=512),\n",
    "                         RandomHorizontalFlipSatellite(A=512),\n",
    "                         RandomVerticalFlipSatellite(W=640, A=512)]\n",
    "\n",
    "    # data\n",
    "    imgs, target = dataset[idx]\n",
    "    street_img, satellite_img = imgs\n",
    "    W, H, A = street_img.shape[2], street_img.shape[1], satellite_img.shape[1]\n",
    "    xc, yc = target[\"location\"][1], target[\"location\"][0] # see GitHub of VIGOR for this formula\n",
    "    \n",
    "    # create plot\n",
    "    fig = plt.figure(figsize=[15, 11])\n",
    "    grid = plt.GridSpec(2, 3, wspace=0.1, hspace=0.1)\n",
    "    ax1 = plt.subplot(grid[0, :2])\n",
    "    ax2 = plt.subplot(grid[0, 2])\n",
    "    ax3 = plt.subplot(grid[1, :2])\n",
    "    ax4 = plt.subplot(grid[1, 2])\n",
    "    \n",
    "    # plot street view\n",
    "    ax1.imshow(street_img.permute(1, 2, 0).numpy(), extent=(0, W, H, 0), zorder=-10)\n",
    "    ax1.set_title('Street View', pad=10, fontsize=24)\n",
    "    ax1.set_xlim(0, W)\n",
    "    ax1.set_ylim(H, 0)\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # plot satellite view\n",
    "    ax2.imshow(satellite_img.permute(1, 2, 0).numpy(), extent=(0, A, A, 0), zorder=-10)\n",
    "    ax2.set_title('Satellite View', pad=10, fontsize=24)\n",
    "    ax2.set_xlim(0, A)\n",
    "    ax2.set_ylim(A, 0)\n",
    "    ax2.axis('off')\n",
    "\n",
    "    # transformation\n",
    "    if Rotate==\"0 degrees\":\n",
    "        imgs, target = visual_transforms[0](imgs, target, 0.25)\n",
    "    elif Rotate==\"90 degrees\":\n",
    "        imgs, target = visual_transforms[0](imgs, target, 0.50)\n",
    "    elif Rotate==\"180 degrees\":\n",
    "        imgs, target = visual_transforms[0](imgs, target, 0.75)\n",
    "    elif Rotate==\"270 degrees\":\n",
    "        imgs, target = visual_transforms[0](imgs, target, 1.00)\n",
    "    if HorizontalFlip==\"Apply\":\n",
    "        visual_transforms[1].prob_threshold = 1\n",
    "        imgs, target = visual_transforms[1](imgs, target)\n",
    "    if VerticalFlip==\"Apply\":\n",
    "        visual_transforms[2].prob_threshold = 1\n",
    "        imgs, target = visual_transforms[2](imgs, target)\n",
    "\n",
    "    # transformed data\n",
    "    street_img, satellite_img = imgs\n",
    "    W, H, A = street_img.shape[2], street_img.shape[1], satellite_img.shape[1]\n",
    "    xc_transformed, yc_transformed = target[\"location\"][1], target[\"location\"][0] # see GitHub of VIGOR for this formula\n",
    "\n",
    "    # plot transformed street view   \n",
    "    ax3.imshow(street_img.permute(1, 2, 0).numpy(), extent=(0, W, H, 0), zorder=-10)\n",
    "    ax3.set_title('Transformed Street View', pad=10, fontsize=24)\n",
    "    ax3.set_xlim(0, W)\n",
    "    ax3.set_ylim(H, 0)\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    # plot transformed satellite view\n",
    "    ax4.imshow(satellite_img.permute(1, 2, 0).numpy(), extent=(0, A, A, 0), zorder=-10)\n",
    "    ax4.set_title('Transformed Satellite View', pad=10, fontsize=24)\n",
    "    ax4.set_xlim(0, A)\n",
    "    ax4.set_ylim(A, 0)\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # plot rays\n",
    "    colors = ['springgreen', 'deepskyblue', 'orange', 'magenta'] # North, East, South, West\n",
    "    \n",
    "    ax1.vlines(x=0.00*W, ymin=0, ymax=H, color=colors[2], linewidth=3, zorder=10) # South\n",
    "    ax1.vlines(x=0.25*W, ymin=0, ymax=H, color=colors[3], linewidth=3, zorder=10) # West\n",
    "    ax1.vlines(x=0.50*W, ymin=0, ymax=H, color=colors[0], linewidth=3, zorder=10) # North\n",
    "    ax1.vlines(x=0.75*W, ymin=0, ymax=H, color=colors[1], linewidth=3, zorder=10) # East\n",
    "    ax1.vlines(x=1.00*W, ymin=0, ymax=H, color=colors[2], linewidth=3, zorder=10) # South\n",
    "    \n",
    "    ax2.scatter(xc, yc, s=150, color=\"yellow\", zorder=20) # Center\n",
    "    ax2.vlines(x=xc, ymin=0, ymax=yc, color=colors[0], linewidth=3, zorder=10) # North\n",
    "    ax2.hlines(y=yc, xmin=xc, xmax=A, color=colors[1], linewidth=3, zorder=10) # East\n",
    "    ax2.vlines(x=xc, ymin=yc, ymax=A, color=colors[2], linewidth=3, zorder=10) # South\n",
    "    ax2.hlines(y=yc, xmin=0, xmax=xc, color=colors[3], linewidth=3, zorder=10) # West\n",
    "    \n",
    "    ax3.vlines(x=0.00*W, ymin=0, ymax=H, color=\"white\", linewidth=3, zorder=10)\n",
    "    ax3.vlines(x=0.25*W, ymin=0, ymax=H, color=\"white\", linewidth=3, zorder=10)\n",
    "    ax3.vlines(x=0.50*W, ymin=0, ymax=H, color=\"white\", linewidth=3, zorder=10)\n",
    "    ax3.vlines(x=0.75*W, ymin=0, ymax=H, color=\"white\", linewidth=3, zorder=10)\n",
    "    ax3.vlines(x=1.00*W, ymin=0, ymax=H, color=\"white\", linewidth=3, zorder=10)\n",
    "\n",
    "    xc, yc = target[\"location\"][1], target[\"location\"][0] # see GitHub of VIGOR for this formula\n",
    "    ax4.scatter(xc_transformed, yc_transformed, s=150, color=\"yellow\", zorder=20) # Center\n",
    "    ax4.vlines(x=xc_transformed, ymin=0, ymax=yc_transformed, color=\"white\", linewidth=3, zorder=10)\n",
    "    ax4.hlines(y=yc_transformed, xmin=xc_transformed, xmax=A, color=\"white\", linewidth=3, zorder=10)\n",
    "    ax4.vlines(x=xc_transformed, ymin=yc_transformed, ymax=A, color=\"white\", linewidth=3, zorder=10)\n",
    "    ax4.hlines(y=yc_transformed, xmin=0, xmax=xc_transformed, color=\"white\", linewidth=3, zorder=10)\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# Folder names\n",
    "streetfolder_resized_name = streetfolder_name+\"_resized\"\n",
    "satellitefolder_resized_name = satellitefolder_name+\"_resized\"\n",
    "\n",
    "\n",
    "# Dataset\n",
    "dataset = VIGORDataset(root=dataset_dir,\n",
    "                       cities=vigor_cities,\n",
    "                       streetfolder_name=streetfolder_resized_name,\n",
    "                       satellitefolder_name=satellitefolder_resized_name,\n",
    "                       combinationfolder_name=combinationfolder_name,\n",
    "                       file_name=\"same_area_balanced_train.txt\",\n",
    "                       transforms=get_transform(normalize=False,\n",
    "                                                train=False,\n",
    "                                                rotate=False,\n",
    "                                                hflip=False,\n",
    "                                                vflip=False,\n",
    "                                                H=320,\n",
    "                                                W=640,\n",
    "                                                A=512),\n",
    "                       only_pos=False)\n",
    "\n",
    "\n",
    "# Widget\n",
    "if DO_INTERACTION:\n",
    "    ipywidgets.interact(lambda idx, Rotate, HFlip, VFlip: plot_visual_transforms(dataset=dataset,\n",
    "                                                                                 idx=idx,\n",
    "                                                                                 Rotate=Rotate,\n",
    "                                                                                 HorizontalFlip=HFlip,\n",
    "                                                                                 VerticalFlip=VFlip),\n",
    "                        idx=range(100),\n",
    "                        Rotate=[\"0 degrees\",\"90 degrees\",\"180 degrees\",\"270 degrees\"],\n",
    "                        HFlip=[\"Don't apply\",\"Apply\"],\n",
    "                        VFlip=[\"Don't apply\",\"Apply\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streetfolder_resized_name = streetfolder_name+\"_resized\"\n",
    "satellitefolder_resized_name = satellitefolder_name+\"_resized\"\n",
    "dataset_traindata = VIGORDataset(root=dataset_dir,\n",
    "                                 cities=[\"NewYork\"],\n",
    "                                 streetfolder_name=streetfolder_resized_name,\n",
    "                                 satellitefolder_name=satellitefolder_resized_name,\n",
    "                                 combinationfolder_name=combinationfolder_name,\n",
    "                                 file_name=\"same_area_balanced_train.txt\",\n",
    "                                 transforms=get_transform(normalize=True,\n",
    "                                                          train=True,\n",
    "                                                          rotate=DO_DATA_AUGMENTATION,\n",
    "                                                          hflip=DO_DATA_AUGMENTATION,\n",
    "                                                          vflip=False,\n",
    "                                                          H=320,\n",
    "                                                          W=640,\n",
    "                                                          A=512),\n",
    "                                 only_pos=DO_POS_ONLY)\n",
    "dataset_testdata = VIGORDataset(root=dataset_dir,\n",
    "                                cities=[\"NewYork\"],\n",
    "                                streetfolder_name=streetfolder_resized_name,\n",
    "                                satellitefolder_name=satellitefolder_resized_name,\n",
    "                                combinationfolder_name=combinationfolder_name,\n",
    "                                file_name=\"same_area_balanced_test.txt\",\n",
    "                                transforms=get_transform(normalize=True,\n",
    "                                                         train=False,\n",
    "                                                         rotate=False,\n",
    "                                                         hflip=False,\n",
    "                                                         vflip=False,\n",
    "                                                         H=320,\n",
    "                                                         W=640,\n",
    "                                                         A=512),\n",
    "                                only_pos=DO_POS_ONLY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. VIGOR baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class SPE_module(nn.Module):\n",
    "    \"\"\" The Spatial-aware Position Embedding (SPE) Module of SAFA. \"\"\"\n",
    "    \n",
    "    def __init__(self, map_height, map_width, add_relu, add_sigmoid):\n",
    "        super().__init__()\n",
    "        \n",
    "        # define linear layers for creating position embedding map P\n",
    "        input_size, hidden_size, output_size = map_height*map_width, map_height*map_width//2, map_height*map_width\n",
    "        self.linear1 = th.nn.Linear(in_features=input_size, out_features=hidden_size, bias=True)\n",
    "        self.linear2 = th.nn.Linear(in_features=hidden_size, out_features=output_size, bias=True)\n",
    "        \n",
    "        # SAFA source code forgot the activation functions\n",
    "        self.relu        = nn.ReLU() if add_relu else None\n",
    "        self.sigmoid     = nn.Sigmoid() if add_sigmoid else None\n",
    "        self.add_relu    = add_relu\n",
    "        self.add_sigmoid = add_sigmoid\n",
    "        \n",
    "    def forward(self, fmaps):\n",
    "        # max-pooling along channels\n",
    "        maxpooled = self.channel_max_pool(fmaps.clone())\n",
    "        \n",
    "        # spatial-aware importance generator\n",
    "        y1 = self.linear1(maxpooled.flatten(start_dim=-2, end_dim=-1))\n",
    "        if self.add_relu:\n",
    "            y1 = self.relu(y1)\n",
    "        y2 = self.linear2(y1)\n",
    "        if self.add_sigmoid:\n",
    "            y2 = self.sigmoid(y2)\n",
    "        P = y2.unsqueeze(dim=1)\n",
    "        \n",
    "        # Frobenius inner product\n",
    "        embedding = th.mul(fmaps.flatten(start_dim=-2, end_dim=-1), P).sum(dim=-1)\n",
    "        \n",
    "        return embedding\n",
    "    \n",
    "    def channel_max_pool(self, feature_map):\n",
    "        maxpooled, indices = th.max(feature_map, axis=-3)\n",
    "        return maxpooled\n",
    "\n",
    "    \n",
    "class SAFA_module(nn.Module):\n",
    "    \"\"\" The Spatial-aware Feature Aggregation (SAFA) Module of SAFA. \"\"\"\n",
    "    \n",
    "    def __init__(self, map_height, map_width, add_relu, add_sigmoid):\n",
    "        super().__init__()\n",
    "        \n",
    "        # define multiple SPE modules (8 in total)\n",
    "        self.SPE1 = SPE_module(map_height, map_width, add_relu, add_sigmoid)\n",
    "        self.SPE2 = SPE_module(map_height, map_width, add_relu, add_sigmoid)\n",
    "        self.SPE3 = SPE_module(map_height, map_width, add_relu, add_sigmoid)\n",
    "        self.SPE4 = SPE_module(map_height, map_width, add_relu, add_sigmoid)\n",
    "        self.SPE5 = SPE_module(map_height, map_width, add_relu, add_sigmoid)\n",
    "        self.SPE6 = SPE_module(map_height, map_width, add_relu, add_sigmoid)\n",
    "        self.SPE7 = SPE_module(map_height, map_width, add_relu, add_sigmoid)\n",
    "        self.SPE8 = SPE_module(map_height, map_width, add_relu, add_sigmoid)\n",
    "\n",
    "    def forward(self, fmaps):\n",
    "        # calculate the embedding for every SPE module\n",
    "        em1 = self.SPE1(fmaps.clone())\n",
    "        em2 = self.SPE2(fmaps.clone())\n",
    "        em3 = self.SPE3(fmaps.clone())\n",
    "        em4 = self.SPE4(fmaps.clone())\n",
    "        em5 = self.SPE5(fmaps.clone())\n",
    "        em6 = self.SPE6(fmaps.clone())\n",
    "        em7 = self.SPE7(fmaps.clone())\n",
    "        em8 = self.SPE8(fmaps.clone())\n",
    "\n",
    "        # create global descriptor by aggregate the embeddings\n",
    "        gd = th.cat((em1, em2, em3, em4, em5, em6, em7, em8), dim=-1)\n",
    "        \n",
    "        # normalize global descriptor\n",
    "        gd = th.div(gd, th.linalg.norm(gd, ord=2, dim=1).unsqueeze(dim=1))\n",
    "        \n",
    "        return gd\n",
    "\n",
    "\n",
    "class CVR(nn.Module):\n",
    "    \"\"\" The Cross-View Regression model of VIGOR. \"\"\"\n",
    "\n",
    "    def __init__(self, street_img_height, street_img_width, sat_img_height, sat_img_width, stride=16,\n",
    "                 add_relu=False, add_sigmoid=False, do_metric_localization=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        # backbones\n",
    "        self.vgg16_street = nn.Sequential(*th_vision.models.vgg16(pretrained=True).features[:-1])\n",
    "        self.vgg16_sat    = nn.Sequential(*th_vision.models.vgg16(pretrained=True).features[:-1])\n",
    "        \n",
    "        # safa modules\n",
    "        self.safa_street = SAFA_module(map_height=street_img_height//stride,\n",
    "                                       map_width=street_img_width//stride,\n",
    "                                       add_relu=add_relu,\n",
    "                                       add_sigmoid=add_sigmoid)\n",
    "        self.safa_sat    = SAFA_module(map_height=sat_img_height//stride,\n",
    "                                       map_width=sat_img_width//stride,\n",
    "                                       add_relu=add_relu,\n",
    "                                       add_sigmoid=add_sigmoid)\n",
    "\n",
    "        # offset prediction\n",
    "        if do_metric_localization:\n",
    "            self.linear1 = th.nn.Linear(in_features=2*4096, out_features=512, bias=True)\n",
    "            self.linear2 = th.nn.Linear(in_features=512, out_features=2, bias=True)\n",
    "            self.relu    = nn.ReLU()\n",
    "        \n",
    "        # setting\n",
    "        self.do_metric_localization = do_metric_localization\n",
    "        \n",
    "    def forward(self, street_imgs, sat_imgs):\n",
    "        # determine global descriptor of street image\n",
    "        fmaps_street = self.vgg16_street(street_imgs)\n",
    "        gds_street = self.safa_street(fmaps_street)\n",
    "        \n",
    "        # determine global descriptor of satellite image\n",
    "        fmaps_sat = self.vgg16_sat(sat_imgs)\n",
    "        gds_sat = self.safa_sat(fmaps_sat)\n",
    "               \n",
    "        if not self.do_metric_localization:\n",
    "            return gds_street, gds_sat\n",
    "        \n",
    "        else:\n",
    "            # determine offset\n",
    "            gds_concatenated = th.cat((gds_street, gds_sat), dim=-1)\n",
    "            delta = self.linear2(self.relu(self.linear1(gds_concatenated)))\n",
    "            \n",
    "            return gds_street, gds_sat, delta\n",
    "\n",
    "\n",
    "def get_CVR_model(add_relu=False, add_sigmoid=False):\n",
    "    model = CVR(street_img_height=320,\n",
    "                street_img_width=640,\n",
    "                sat_img_height=512,\n",
    "                sat_img_width=512,\n",
    "                add_relu=add_relu,\n",
    "                add_sigmoid=add_sigmoid, \n",
    "                do_metric_localization=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training, Validation, and Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_for_loss(model, criterion, optimizer, data_loader, device):\n",
    "    A = 512\n",
    "    \n",
    "    # variable to store the loss and pixel difference\n",
    "    total_loss   = 0\n",
    "    total_pxdiff = 0\n",
    "\n",
    "    # set model to train mode\n",
    "    model.train()\n",
    "\n",
    "    for image_pairs, targets in data_loader:\n",
    "        street_imgs = th.stack([street_img.to(device) for street_img, _ in image_pairs])\n",
    "        sat_imgs = th.stack([sat_img.to(device) for _, sat_img in image_pairs])\n",
    "        targets = th.stack([target[\"location\"] for target in targets]).to(device)\n",
    "\n",
    "        # predict and loss\n",
    "        gds_street, gds_sat, delta_preds = model(street_imgs, sat_imgs)\n",
    "        loss = criterion(delta_preds, targets/A)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # add loss and pixel difference\n",
    "        total_loss   += loss.item()\n",
    "        total_pxdiff += th.linalg.norm(targets-A*delta_preds, ord=2, dim=1).mean().item()\n",
    "\n",
    "    # average loss and pixel difference\n",
    "    avg_loss = total_loss/len(data_loader)\n",
    "    avg_pxdiff = total_pxdiff/len(data_loader)\n",
    "\n",
    "    return avg_loss, avg_pxdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model_for_loss(model, criterion, data_loader, device):\n",
    "    A = 512\n",
    "    \n",
    "    # variable to store the loss and pixel difference\n",
    "    total_loss   = 0\n",
    "    total_pxdiff = 0\n",
    "\n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # disable gradient calculation\n",
    "    with th.no_grad():           \n",
    "        for image_pairs, targets in data_loader:\n",
    "            street_imgs = th.stack([street_img.to(device) for street_img, _ in image_pairs])\n",
    "            sat_imgs = th.stack([sat_img.to(device) for _, sat_img in image_pairs])\n",
    "            targets = th.stack([target[\"location\"] for target in targets]).to(device)\n",
    "\n",
    "            # predict and loss\n",
    "            gds_street, gds_sat, delta_preds = model(street_imgs, sat_imgs)\n",
    "            loss = criterion(delta_preds, targets/A)\n",
    "\n",
    "            # add loss and pixel difference\n",
    "            total_loss   += loss.item()\n",
    "            total_pxdiff += th.linalg.norm(targets-A*delta_preds, ord=2, dim=1).mean().item()\n",
    "\n",
    "    # average loss and pixel difference\n",
    "    avg_loss = total_loss/len(data_loader)\n",
    "    avg_pxdiff = total_pxdiff/len(data_loader)\n",
    "\n",
    "    return avg_loss, avg_pxdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_for_pixels(model, data_loader, device):\n",
    "    A = 512\n",
    "\n",
    "    # variable to store test result\n",
    "    test_result = th.empty([0,4]).to(device)\n",
    "    total_loss   = 0\n",
    "    total_pxdiff = 0\n",
    "\n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # disable gradient calculation\n",
    "    with th.no_grad():           \n",
    "        for image_pairs, targets in data_loader:\n",
    "            street_imgs = th.stack([street_img.to(device) for street_img, _ in image_pairs])\n",
    "            sat_imgs = th.stack([sat_img.to(device) for _, sat_img in image_pairs])\n",
    "            targets = th.stack([target[\"location\"] for target in targets]).to(device)\n",
    "\n",
    "            # predict\n",
    "            gds_street, gds_sat, delta_preds = model(street_imgs, sat_imgs)\n",
    "\n",
    "            # append predictions and targets to test result\n",
    "            test_result = th.cat((test_result, th.cat((A*delta_preds, targets), dim=1)), dim=0)\n",
    "\n",
    "    # convert to numpy array\n",
    "    test_result = test_result.cpu().numpy()\n",
    "    \n",
    "    return test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_TRAIN:\n",
    "    # set seed for repetitiveness\n",
    "    th.manual_seed(1)\n",
    "\n",
    "\n",
    "    # utility function for data loader\n",
    "    # convert batch from [(imgs1, target1), (imgs2, target2)] into ((imgs1, imgs2), (target1, target2))\n",
    "    def collate_fn(batch):\n",
    "        return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "    # split the dataset in train, validation and test dataset\n",
    "    if DO_FULL_DATASET:\n",
    "        len_train = len(dataset_traindata)\n",
    "    else:\n",
    "        len_train = CUSTOM_DATASET_LENGTH\n",
    "    dataset_train = th_data.Subset(dataset_traindata, list(range(0, int(0.8*len_train), 1)))\n",
    "    dataset_val   = th_data.Subset(dataset_traindata, list(range(int(0.8*len_train), len_train, 1)))\n",
    "    dataset_test  = dataset_testdata\n",
    "\n",
    "\n",
    "    # create data loaders\n",
    "    data_loader_train = th_data.DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "    data_loader_val   = th_data.DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "    data_loader_test  = th_data.DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    \n",
    "    # model\n",
    "    model = get_CVR_model(ADD_RELU, ADD_SIGMOID).to(device)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    \n",
    "    # criterion and optimizer\n",
    "    criterion = nn.MSELoss(reduction='mean')\n",
    "    params    = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = th.optim.Adam(params, lr=1e-5, betas=(0.9, 0.999))\n",
    "\n",
    "    \n",
    "    # save directory\n",
    "    if DO_POS_ONLY:\n",
    "        if ADD_RELU and ADD_SIGMOID:\n",
    "            name = \"pos_relusigmoid\"\n",
    "        elif ADD_RELU and not ADD_SIGMOID:\n",
    "            name = \"pos_relu\"\n",
    "        else:\n",
    "            name = \"pos_no\"\n",
    "    else:\n",
    "        if ADD_RELU and ADD_SIGMOID:\n",
    "            name = \"semipos_relusigmoid\"\n",
    "        elif ADD_RELU and not ADD_SIGMOID:\n",
    "            name = \"semipos_relu\"\n",
    "        else:\n",
    "            name = \"semipos_no\"\n",
    "    saving_time = time.strftime(\"%Y-%m-%d-%H-%M\")\n",
    "    base_save_dir = \"/scratch/zxia/MSc/Ted/checkpoints/VIGOR_DEVEL_2022-04-07\"\n",
    "    if not os.path.isdir(base_save_dir):\n",
    "        os.mkdir(base_save_dir)\n",
    "    model_save_dir = os.path.join(base_save_dir, f\"model_{name}_{saving_time}.pt\")\n",
    "    loss_save_dir = os.path.join(base_save_dir, f\"loss_{name}_{saving_time}.npy\")\n",
    "    pxdiff_save_dir = os.path.join(base_save_dir, f\"pxdiff_{name}_{saving_time}.npy\")\n",
    "    print(f\"The model will be saved as {model_save_dir}\")\n",
    "    print(f\"The losses will be saved as {loss_save_dir}\")\n",
    "    print(f\"The pixel differences will be saved as {pxdiff_save_dir}\")\n",
    "    print()\n",
    "\n",
    "    \n",
    "    # training variables\n",
    "    NUM_EPOCHS = 20\n",
    "\n",
    "    # early stopping implementation\n",
    "    best_val_loss = float('inf')\n",
    "    patience      = 5\n",
    "    patience_cnt  = 0\n",
    "    \n",
    "    # store and save losses\n",
    "    losses, pxdiffs = [], []\n",
    "\n",
    "    # compute initial loss on validation dataset\n",
    "    val_loss, val_pxdiff = validate_model_for_loss(model, criterion, data_loader_val, device)\n",
    "    losses.append((np.nan, val_loss))\n",
    "    pxdiffs.append((np.nan, val_pxdiff))\n",
    "    print(f\"Epoch 00 - Val loss: {np.round(val_loss, 3)} | Val pixel difference: {np.round(val_pxdiff, 3)}\")\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # train for one epoch\n",
    "        train_loss, train_pxdiff = train_model_for_loss(model, criterion, optimizer, data_loader_train, device)\n",
    "\n",
    "        # evaluate on validation dataset\n",
    "        val_loss, val_pxdiff = validate_model_for_loss(model, criterion, data_loader_val, device)\n",
    "\n",
    "        # store and save losses\n",
    "        losses.append((train_loss, val_loss))\n",
    "        pxdiffs.append((train_pxdiff, val_pxdiff))\n",
    "        np.save(loss_save_dir, np.array(losses))\n",
    "        np.save(pxdiff_save_dir, np.array(pxdiffs))\n",
    "\n",
    "        # print losses\n",
    "        epoch_str = f\"{epoch+1}\".zfill(2)\n",
    "        print(f\"Epoch {epoch_str} - Train and Val loss: {np.round(train_loss, 3)} ; {np.round(val_loss, 3)} | Train and Val pixel difference: {np.round(train_pxdiff, 3)} ; {np.round(val_pxdiff, 3)}\")\n",
    "\n",
    "        # apply early stopping\n",
    "        if val_loss<best_val_loss:\n",
    "            patience_cnt = 0\n",
    "            best_val_loss = val_loss\n",
    "\n",
    "            # save model\n",
    "            th.save(model.state_dict(), model_save_dir)\n",
    "\n",
    "        else:\n",
    "            patience_cnt += 1\n",
    "\n",
    "            if patience_cnt==patience:              \n",
    "                # stop training\n",
    "                break\n",
    "\n",
    "    print(f\"\\nThe files have been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_TRAIN and DO_TEST:\n",
    "    # save directory\n",
    "    test_save_dir = os.path.join(base_save_dir, f\"testresult_{name}_{saving_time}.npy\")\n",
    "    print(f\"The test result will be saved as {test_save_dir}\")\n",
    "    print()\n",
    "    \n",
    "    # test on test dataset\n",
    "    test_result =  test_model_for_pixels(model, data_loader_test, device)\n",
    "    \n",
    "    # save output\n",
    "    np.save(test_save_dir, test_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
